"""
CSVç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æ—¢å­˜CSVã®èª­ã¿è¾¼ã¿ã€æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ã€ä¿å­˜ã‚’ç®¡ç†
"""

import os
from typing import List, Dict, Optional, Set
import pandas as pd
from datetime import datetime


class CSVManager:
    """CSVèª­ã¿æ›¸ãã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.column_order = ['ç•ªå·', 'å…¬é–‹æ—¥', 'ã‚¿ã‚¤ãƒˆãƒ«', 'æœ¬æ–‡', 'ä¾¡æ ¼', 'è³¼å…¥çŠ¶æ³', 'URL']
    
    def load_existing_csv(self, csv_path: str) -> Dict[str, any]:
        """æ—¢å­˜CSVã‚’èª­ã¿è¾¼ã¿ã€ãƒ‡ãƒ¼ã‚¿ã¨çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™"""
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            
            # çµ±è¨ˆæƒ…å ±
            if 'URL' in df.columns:
                existing_urls = set(df['URL'].dropna().tolist())
            else:
                existing_urls = set()  # URLåˆ—ãŒãªã„å ´åˆã¯ç©ºã®set
            
            stats = {
                'total_articles': len(df),
                'date_range': self._get_date_range(df),
                'latest_date': self._get_latest_date(df),
                'existing_urls': existing_urls,
                'has_url_column': 'URL' in df.columns
            }
            
            print(f"âœ… æ—¢å­˜CSVèª­ã¿è¾¼ã¿å®Œäº†: {csv_path}")
            print(f"ğŸ“Š è¨˜äº‹æ•°: {stats['total_articles']}")
            print(f"ğŸ“… æœŸé–“: {stats['date_range']}")
            
            return {
                'dataframe': df,
                'stats': stats
            }
            
        except Exception as e:
            raise Exception(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def extract_existing_urls(self, csv_path: str) -> Set[str]:
        """æ—¢å­˜CSVã‹ã‚‰URLä¸€è¦§ã‚’æŠ½å‡º"""
        data = self.load_existing_csv(csv_path)
        return data['stats']['existing_urls']
    
    def merge_and_save(self, existing_csv_path: str, new_articles: List[Dict], 
                      output_path: Optional[str] = None) -> Dict[str, any]:
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨æ–°è¦è¨˜äº‹ã‚’ãƒãƒ¼ã‚¸ã—ã¦ä¿å­˜"""
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        existing_data = self.load_existing_csv(existing_csv_path)
        existing_df = existing_data['dataframe']
        
        if not new_articles:
            print("ğŸ“ æ–°è¦è¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä¿æŒã—ã¾ã™ã€‚")
            return {
                'success': True,
                'filename': existing_csv_path,
                'new_articles_count': 0,
                'total_articles_count': len(existing_df)
            }
        
        # æ–°è¦è¨˜äº‹ã‚’DataFrameã«å¤‰æ›
        new_df = self._create_dataframe_from_articles(new_articles, 
                                                     start_number=len(existing_df) + 1)
        
        # æ—¢å­˜DFã«URLåˆ—ãŒãªã„å ´åˆã¯è¿½åŠ 
        if 'URL' not in existing_df.columns:
            existing_df['URL'] = ''
            print("â„¹ï¸  æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«URLåˆ—ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        merged_df = pd.concat([existing_df, new_df], ignore_index=True)
        
        # ç•ªå·ã‚’å†æŒ¯ã‚Šï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        merged_df['ç•ªå·'] = range(1, len(merged_df) + 1)
        
        # å‡ºåŠ›ãƒ‘ã‚¹æ±ºå®š
        if output_path is None:
            # outputãƒ•ã‚©ãƒ«ãƒ€ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
            os.makedirs("output", exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            base_name = os.path.splitext(os.path.basename(existing_csv_path))[0]
            output_path = f"output/{base_name}_updated_{timestamp}.csv"
        
        # ä¿å­˜
        merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        # çµæœæƒ…å ±
        file_size = os.path.getsize(output_path)
        file_size_mb = file_size / (1024 * 1024)
        
        result = {
            'success': True,
            'filename': output_path,
            'new_articles_count': len(new_articles),
            'total_articles_count': len(merged_df),
            'file_size_mb': round(file_size_mb, 1)
        }
        
        print(f"âœ… ãƒãƒ¼ã‚¸ãƒ»ä¿å­˜å®Œäº†!")
        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        print(f"ğŸ“ˆ æ–°è¦è¨˜äº‹: {result['new_articles_count']}")
        print(f"ğŸ“Š ç·è¨˜äº‹æ•°: {result['total_articles_count']}")
        print(f"ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {result['file_size_mb']} MB")
        
        return result
    
    def _create_dataframe_from_articles(self, articles: List[Dict], start_number: int = 1) -> pd.DataFrame:
        """è¨˜äº‹ãƒªã‚¹ãƒˆã‹ã‚‰DataFrameã‚’ä½œæˆ"""
        df_data = []
        for i, article in enumerate(articles):
            df_data.append({
                'ç•ªå·': start_number + i,
                'å…¬é–‹æ—¥': article.get('date', ''),
                'ã‚¿ã‚¤ãƒˆãƒ«': article.get('title', ''),
                'æœ¬æ–‡': article.get('content', ''),
                'ä¾¡æ ¼': article.get('price', ''),
                'è³¼å…¥çŠ¶æ³': article.get('purchase_status', ''),
                'URL': article.get('url', '')
            })
        
        return pd.DataFrame(df_data)
    
    def _get_date_range(self, df: pd.DataFrame) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ç¯„å›²ã‚’å–å¾—"""
        if 'å…¬é–‹æ—¥' not in df.columns:
            return "ä¸æ˜"
        
        dates = pd.to_datetime(df['å…¬é–‹æ—¥'], errors='coerce').dropna()
        if len(dates) == 0:
            return "ä¸æ˜"
        
        min_date = dates.min().strftime('%Y-%m-%d')
        max_date = dates.max().strftime('%Y-%m-%d')
        return f"{min_date} ã€œ {max_date}"
    
    def _get_latest_date(self, df: pd.DataFrame) -> Optional[str]:
        """æœ€æ–°ã®è¨˜äº‹æ—¥ä»˜ã‚’å–å¾—"""
        if 'å…¬é–‹æ—¥' not in df.columns:
            return None
        
        dates = pd.to_datetime(df['å…¬é–‹æ—¥'], errors='coerce').dropna()
        if len(dates) == 0:
            return None
        
        return dates.max().strftime('%Y-%m-%d %H:%M:%S')
    
    def validate_csv_format(self, csv_path: str) -> bool:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’æ¤œè¨¼"""
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            
            # URLåˆ—ã®æœ‰åŠ¹æ€§ç¢ºèª
            if 'URL' in df.columns:
                valid_urls = df['URL'].dropna()
                non_empty_urls = [url for url in valid_urls if url.strip()]
                
                if len(non_empty_urls) == 0:
                    print("â„¹ï¸  URLãŒç©ºã§ã™ï¼ˆå…¨è¨˜äº‹ã‚’æ–°è¦ã¨ã—ã¦æ‰±ã„ã¾ã™ï¼‰")
            else:
                print("â„¹ï¸  URLåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå…¨è¨˜äº‹ã‚’æ–°è¦ã¨ã—ã¦æ‰±ã„ã¾ã™ï¼‰")
            
            print(f"âœ… CSVå½¢å¼æ¤œè¨¼: æ­£å¸¸ ({len(df)}è¨˜äº‹)")
            return True
            
        except Exception as e:
            print(f"âŒ CSVæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False