#!/usr/bin/env python3
"""
ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ - å•é¡Œã‚’ç‰¹å®šã™ã‚‹ãŸã‚
"""

import asyncio
from playwright.async_api import async_playwright
import re
from urllib.parse import urljoin

async def debug_note_page(author_url: str):
    """Noteè‘—è€…ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒãƒƒã‚°"""
    
    playwright = await async_playwright().start()
    browser = await playwright.chromium.launch(headless=False)
    page = await browser.new_page()
    
    try:
        print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°é–‹å§‹: {author_url}")
        
        # ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
        await page.goto(author_url, wait_until="domcontentloaded", timeout=30000)
        await page.wait_for_timeout(5000)
        
        print(f"ğŸ“„ ç¾åœ¨ã®URL: {page.url}")
        print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {await page.title()}")
        
        # ã‚ˆã‚Šè©³ç´°ãªãƒªãƒ³ã‚¯è§£æ
        all_links = await page.query_selector_all('a[href]')
        print(f"ğŸ”— å…¨ãƒªãƒ³ã‚¯æ•°: {len(all_links)}")
        
        note_links = []
        other_links = []
        
        for i, link in enumerate(all_links):
            href = await link.get_attribute('href')
            if href:
                text = await link.text_content() or ""
                # noteè¨˜äº‹ãƒªãƒ³ã‚¯ã®æ¤œå‡º
                if '/n/' in href and re.match(r'.*/n/[a-zA-Z0-9_-]+', href):
                    full_url = urljoin("https://note.com", href)
                    full_url = full_url.split('?')[0].split('#')[0]
                    if full_url not in note_links:
                        note_links.append(full_url)
                        print(f"  ğŸ“ è¨˜äº‹: {full_url} - '{text[:50]}...'")
                elif 'note.com' in href or href.startswith('/'):
                    other_links.append((href, text[:50]))
        
        print(f"\nğŸ“ Noteè¨˜äº‹ãƒªãƒ³ã‚¯: {len(note_links)}å€‹")
        print(f"ğŸ”— ãã®ä»–ã®ãƒªãƒ³ã‚¯: {len(other_links)}å€‹")
        
        # ãã®ä»–ã®ãƒªãƒ³ã‚¯ã‚’è©³ç´°è¡¨ç¤º
        if len(other_links) > 0:
            print("\nğŸ” ãã®ä»–ã®ãƒªãƒ³ã‚¯è©³ç´°:")
            for href, text in other_links[:10]:  # æœ€åˆã®10å€‹ã ã‘è¡¨ç¤º
                print(f"  {href} - '{text}...'")
        
        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦è¿½åŠ ã®è¨˜äº‹ã‚’èª­ã¿è¾¼ã‚€
        print("\nğŸ”„ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦è¿½åŠ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        for i in range(3):
            await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
            await page.wait_for_timeout(2000)
            
        # å†åº¦ãƒªãƒ³ã‚¯ã‚’å–å¾—
        all_links_after = await page.query_selector_all('a[href]')
        print(f"ğŸ”— ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¾Œã®ãƒªãƒ³ã‚¯æ•°: {len(all_links_after)}")
        
        note_links_after = []
        for link in all_links_after:
            href = await link.get_attribute('href')
            if href and '/n/' in href and re.match(r'.*/n/[a-zA-Z0-9_-]+', href):
                full_url = urljoin("https://note.com", href)
                full_url = full_url.split('?')[0].split('#')[0]
                if full_url not in note_links_after:
                    note_links_after.append(full_url)
        
        print(f"ğŸ“ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¾Œã®è¨˜äº‹ãƒªãƒ³ã‚¯: {len(note_links_after)}å€‹")
        note_links = note_links_after
        
        print(f"\nâœ… Noteè¨˜äº‹ãƒªãƒ³ã‚¯ ({len(note_links)}å€‹):")
        for i, url in enumerate(note_links, 1):
            print(f"  {i}: {url}")
            
        # ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’ç¢ºèª
        print(f"\nğŸ—ï¸  ãƒšãƒ¼ã‚¸æ§‹é€ :")
        
        # ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚»ãƒ¬ã‚¯ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
        selectors_to_check = [
            ('article', 'articleè¦ç´ '),
            ('.note-common-styles__textnote-wrapper', 'noteè¨˜äº‹ãƒ©ãƒƒãƒ‘ãƒ¼'),
            ('.p-article', 'p-article'),
            ('[data-testid="article"]', 'ãƒ†ã‚¹ãƒˆIDè¨˜äº‹'),
            ('.o-noteContentText', 'noteæœ¬æ–‡'),
        ]
        
        for selector, description in selectors_to_check:
            elements = await page.query_selector_all(selector)
            print(f"  {description}: {len(elements)}å€‹")
            
        input("\nEnterã‚­ãƒ¼ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¾ã™...")
        
    finally:
        await browser.close()

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("ä½¿ã„æ–¹: python debug_scraper.py <author_url>")
        sys.exit(1)
        
    asyncio.run(debug_note_page(sys.argv[1]))