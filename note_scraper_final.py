#!/usr/bin/env python3
"""
Note Scraper Final - å®Œå…¨ç‰ˆ
Noteè¨˜äº‹ã‚’å–å¾—ã—ã¦CSVã«å‡ºåŠ›
å®Œæˆãƒ‡ãƒ¼ã‚¿ã®å“è³ªã§æœ¬æ–‡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®Ÿè£…
"""

import asyncio
import argparse
import time
from src import NoteScraper


def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(description='Noteè¨˜äº‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('profile_url', help='ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«URL (ä¾‹: https://note.com/ihayato)')
    parser.add_argument('--login', action='store_true', help='æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--no-headless', action='store_true', help='ãƒ–ãƒ©ã‚¦ã‚¶ã‚’è¡¨ç¤ºã™ã‚‹')
    parser.add_argument('--limit', type=int, help='å–å¾—è¨˜äº‹æ•°ã®ä¸Šé™')
    
    return parser.parse_args()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    args = parse_arguments()
    
    # headlessãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆ--no-headlessãŒæŒ‡å®šã•ã‚ŒãŸã‚‰Falseï¼‰
    headless = not args.no_headless
    
    scraper = NoteScraper(headless=headless)
    result = await scraper.run(args.profile_url, limit=args.limit, manual_login=args.login)
    
    if result['success']:
        print(f"\nğŸ‰ å®Ÿè¡Œå®Œäº†!")
        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {result['filename']}")
        print(f"ğŸ“Š è¨˜äº‹æ•°: {result['article_count']}")
        print(f"ğŸ’¾ ã‚µã‚¤ã‚º: {result['file_size_mb']} MB")
    else:
        print(f"\nâŒ å®Ÿè¡Œå¤±æ•—: {result['error']}")


if __name__ == "__main__":
    asyncio.run(main())